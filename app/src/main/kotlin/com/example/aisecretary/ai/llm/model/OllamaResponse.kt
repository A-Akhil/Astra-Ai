package com.example.aisecretary.ai.llm.model

/**
 * Represents the response received from the AI after sending a prompt.
 *
 * This class contains the actual reply text along with metadata such as timing,
 * model used, and token evaluation stats.
 *
 * Example usage:
 * ```
 * val response = OllamaResponse(
 *     model = "llama3",
 *     created_at = "2025-08-03T12:45:00Z",
 *     response = "Sure! Kotlin is a modern programming language...",
 *     done = true
 * )
 * println(response.response)
 * ```
 *
 * @property model The name of the AI model used to generate the response.
 * @property created_at The timestamp when the response was created (in ISO 8601 format).
 * @property response The actual text reply generated by the AI.
 * @property done Indicates whether the AI has completed its response.
 * @property context (Optional) Internal token list used for continuing conversations.
 * @property total_duration (Optional) Total time (in nanoseconds) taken for the full request.
 * @property load_duration (Optional) Time taken to load the model (in nanoseconds).
 * @property prompt_eval_count (Optional) Number of tokens in the input prompt.
 * @property prompt_eval_duration (Optional) Time taken to evaluate the prompt (in nanoseconds).
 * @property eval_count (Optional) Number of tokens generated in the response.
 * @property eval_duration (Optional) Time taken to generate the response (in nanoseconds).
 */
data class OllamaResponse(
    val model: String,
    val created_at: String,
    val response: String,
    val done: Boolean,
    val context: List<Int>? = null,
    val total_duration: Long? = null,
    val load_duration: Long? = null,
    val prompt_eval_count: Int? = null,
    val prompt_eval_duration: Long? = null,
    val eval_count: Int? = null,
    val eval_duration: Long? = null
)

data class OllamaResponse(
    val model: String,
    val created_at: String,
    val response: String,
    val done: Boolean,
    val context: List<Int>? = null,
    val total_duration: Long? = null,
    val load_duration: Long? = null,
    val prompt_eval_count: Int? = null,
    val prompt_eval_duration: Long? = null,
    val eval_count: Int? = null,
    val eval_duration: Long? = null
)